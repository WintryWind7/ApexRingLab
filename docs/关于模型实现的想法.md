# 关于模型实现的想法

## 问题特性分析

### 1. 确定性映射 vs 不确定性输入

**数据特性**：
- 通过重复数据验证：相同的 Ring1 → 100% 相同的 Ring2 和 Ring3
- 毒圈刷新是**完全确定性的映射**，不存在随机性

**实际应用场景**：
- **训练数据**：Ring1 坐标精确 → Ring2 坐标精确
- **实际使用**：Ring1 坐标有误差（约 ±200 像素） → Ring2 位置不确定
- **核心矛盾**：用确定性数据训练，但要处理不确定性输入并输出概率分布

### 2. 泛化能力要求

- 不可能覆盖所有可能的 Ring1 位置（地图空间约 20000×20000）
- 当前数据量：~180 条去重数据
- 必须对**未见过的位置**有合理预测
- 需要学习**平滑的映射关系**

### 3. 空间约束

- Ring2 必须在 Ring1 内部
- 距离约束：`sqrt((x2-x1)² + (y2-y1)²) + r2 <= r1`
- 半径固定：每张地图的各级圈半径是固定值

### 4. 多地图统一建模

**决策**：采用统一建模（单个模型处理 3 张地图）

**理由**：
- 数据量考虑：分开建模每个模型只有 ~60 条数据，太少
- 半径隐式编码：r1 的值已经唯一标识地图
  - `r1=4894` → `mp_rr_tropic_island_mu2`
  - `r1=5036` → `mp_rr_district`
  - `r1=4825` → `mp_rr_desertlands_hu`
- 可以学习跨地图的通用规律

**输入输出设计**：
- **输入**：`[x1, y1, r1]` - 3 个特征
- **输出**：`[x2, y2]` - 2 个特征（r2 从地图配置获取）

## 核心难点

### 难点 1：输入噪声传播
- 输入误差 ±200 像素 → 输出误差可能更大
- 需要量化这种误差传播
- 需要输出概率分布而非单点预测

### 难点 2：稀疏数据的泛化
- 数据稀疏区域如何合理预测？
- 如何避免过拟合？

### 难点 3：输出不确定性量化
- 如何从确定性模型得到概率分布？
- 蒙特卡洛采样等方法的应用

## 实现策略

### 阶段 1：Baseline 模型（线性回归）

**目标**：
- 验证数据是否有规律
- 建立误差基准
- 快速实现，作为后续对比

**预期效果**：
- 训练误差：100-300 像素
- 测试误差：200-500 像素

### 阶段 2：处理输入不确定性

**训练策略**：
- 数据增强：训练时给 (x1, y1) 加入噪声，模拟实际输入误差
- r1 保持精确（已知准确值）

**推理策略**：
- 蒙特卡洛采样：在输入误差范围内采样多次
- 统计输出分布，生成概率热力图

### 阶段 3：提升模型能力

**可选方案**：
- 非线性模型（MLP、K近邻）
- 加入空间约束（后处理或损失函数）
- 评估不同区域的预测质量

## 评估方法

**主要指标**：
- 预测误差（像素距离）：`sqrt((x_pred - x_true)² + (y_pred - y_true)²)`

**分析维度**：
- 不同地图的表现
- 不同位置区域的表现（数据密集 vs 稀疏）
- 加噪声后的鲁棒性

## 项目结构规划

```
model/
├── data/
│   ├── dataset.py          # 数据加载、预处理
│   └── augmentation.py     # 噪声增强
├── models/
│   ├── linear_model.py     # 线性回归 baseline
│   ├── mlp_model.py        # 神经网络
│   └── knn_model.py        # K近邻
├── training/
│   ├── trainer.py          # 训练逻辑
│   └── loss.py             # 损失函数
├── inference/
│   ├── predictor.py        # 预测器
│   └── uncertainty.py      # 不确定性量化（蒙特卡洛）
└── evaluation/
    ├── metrics.py          # 评估指标
    └── visualize.py        # 可视化
```

---

## 附录：早期方案探索（已废弃）

以下是早期考虑的分类模型方案，因精度和计算量问题已不采用，保留作为参考。

## 目标

实现类似 Sabaki + Leela 的效果：在地图上显示毒圈预测的概率分布热力图，并高亮 Top-K 个高概率候选点。

## 预测任务

- **模式 A**：输入第 1 级毒圈 → 预测第 2、3 级
- **模式 B**：输入第 1、2 级毒圈 → 预测第 3 级

暂不考虑第 4 级。

## 方案对比

### 方案 1：分类模型（网格化）

**做法**：
- 将地图划分为 N×N 网格（如 128×128、256×256）
- 模型输出每个网格的概率（Softmax，总和为 1）
- 使用交叉熵损失训练

**优势**：
- 天然输出概率分布，符合可视化需求
- 可以直接绘制热力图
- 类似围棋 AI 的做法，成熟可靠

**问题**：
- **精度受限于网格大小**
  - 128×128：每格 128 坐标单位（太粗糙）
  - 256×256：每格 64 坐标单位（勉强可用）
  - 512×512：每格 32 坐标单位（较精确，但输出 262,144 类）
  - 4096×4096：每格 4 坐标单位（理想精度，但输出 16,777,216 类，不现实）

- **计算量问题**
  - 网格越大，Softmax 计算量越大
  - 显存需求随网格平方增长

### 方案 2：回归模型

**做法**：
- 直接预测坐标 (x, y)
- 使用 MSE 或 Smooth L1 损失

**问题**：
- **无法输出概率分布**
- 只能预测一个点，无法展示多个候选位置
- 不符合"显示热力图"的需求

### 方案 3：混合密度网络（MDN）

**做法**：
- 输出 K 个高斯分布的混合：每个分布包含 (μx, μy, σx, σy, weight)
- 可以表示多个候选点及其不确定性

**问题**：
- 实现复杂
- 需要预先定义混合数量 K
- 热力图需要手动渲染高斯分布，不如分类模型直观

### 方案 4：粗网格 + 上采样可视化

**做法**：
- 训练时输出 256×256 概率图
- 推理时用双线性插值上采样到 4096×4096 显示

**优势**：
- 训练简单（256×256）
- 可视化精细（4096×4096）
- 热力图平滑自然

**问题**：
- **实际预测精度仍然是 64 单位**（受限于 256 网格）
- 上采样只是视觉效果，不能提高真实精度
- 预测的坐标只能是 256 个网格中心之一

### 方案 5：两阶段预测（粗定位 + 精细回归）

**做法**：
- **阶段 1**：粗定位模型输出 256×256 概率图，找到 Top-5 候选区域
- **阶段 2**：精细回归模型对每个候选区域预测偏移量 (Δx, Δy)
- 最终坐标 = 区域中心 + 偏移量

**优势**：
- 保留概率分布的可视化（热力图）
- 精度不受网格限制（回归可以输出任意坐标）
- 计算量可控（粗定位只需 256×256）

**问题**：
- 需要训练两个模型
- 实现复杂度较高
- 阶段 1 的错误会影响阶段 2（如果真实位置不在 Top-5 中）

**可视化方案**：
- 上采样粗定位热力图到 4096×4096
- 在精确坐标位置叠加高斯分布峰值
- 既有全局概率分布，又有精确的候选点

### 方案 6：分层网络（渐进式上采样）

**做法**：
- 类似图像分割网络
- Encoder 提取特征 → Decoder 逐步上采样
- 64×64 → 128×128 → 256×256 → 512×512

**优势**：
- 可以输出更高分辨率（512×512）
- 渐进式生成，计算相对可控

**问题**：
- 网络结构复杂
- 训练时间长
- 仍然无法达到 4096×4096 的真实精度

## 核心矛盾

**需求**：4096×4096 的精细热力图（每格 4 坐标单位）

**现实**：
- 直接输出 4096×4096 = 1600 万类，计算不可行
- 低分辨率网格（256×256）精度不够
- 上采样只是视觉效果，不能提高预测精度

